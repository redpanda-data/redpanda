include "../filesystem/wal.fbs";

namespace raft;

struct server_capabilities {
  min_version: short;
  max_version: short;
}

struct server {
  id:           long;
  capabilities: server_capabilities;
}

table configuration_request {
  ns: long;
  topic: long;
  partition: int;

  /// The servers in a **stable** configuration, or the **old** servers
  /// in a transitional configuration
  nodes:[server];

  /// servers **not present in a stable** configuration, or **new**
  /// servers in a transitional configuration
  learners:[server];
}
table configuration_reply {
}


struct entry_metadata {
  term:      ulong;
  server_id: ulong;
}
table entry {
  meta: entry_metadata;
  /// The index for the entry. Used by followers to check they've got
  /// an entry at the right index. (like kafka-offset?)
  ///
  index: ulong;
  /// the payload to save
  put: wal_put_request;
}



// then you can do std::vector | std::sort() | std::unique()

table vote_request {
  ns: long;
  topic: long;
  partition: int;


  /// \brief request of the caller, so if it re-requests the vote from
  /// the callee, the server will respond granted
  /// lookup against configuration
  server_id: ulong;

  /// \brief caller's term
  term: ulong;

  /// \brief term of last entry in callers log.
  /// used to compare completeness
  last_log_term: ulong;

  /// \brief id of last entry in the caller's log.
  /// used to compare log completeness
  last_log_index: ulong;
}
table vote_reply {
  ns: long;
  topic: long;
  partition: int;


  /// \brief calee's term, for caller to update itself.
  term: ulong;

  /// True if the follower granted the candidate it's vote, false otherwise
  granted: bool;

  /// set to true if the caller's log is as up to date as the recipient's
  /// - extension on raft. see Diego's phd dissertation, section 9.6
  /// - "Preventing disruptions when a server rejoins the cluster"
  log_ok: bool;
}

table append_entries_request {
  ns: long;
  topic: long;
  partition: int;


  /// id of leader (caller), so the follower can redirect clients
  server_id: ulong;
  /// caller's term
  term: ulong;
  /// log entries to store or empty for heartbeat
  entries: [entry];

  /// TODO(agallego) - ask about this method on the mailing list
  ///  -... so why would a request to append entries have the follower
  /// (me/this server) commit index - maybe used when entries are empty...
  /// write a more formal description, but basically you can always append
  /// entries, however advancing the index is the key here
  ///
  /// last committed entry that the follower has, so the follower can advance
  /// it's state machine
  commit_index: ulong;
}

table append_entries_reply {
  /// callee's term, for the caller to upate itself
  term: ulong;
  /// The recipient's last log index after it applied THIS rpc's changes to the
  /// log. This is used to speed up finding the correct value for the nextIndex
  /// with a follower that is far behind a leader
  last_log_index: ulong;

  /// send back to the leader to inform what code the follower is running
  // the range is inclusive between min and max;
  capabilities: server_capabilities;
}

table install_snapshot_request {
  /// \brief xxhash64(topic:string, partition:uint32_t)
  ///
  tpidx: ulong (key);


  /// id of the caller/leader, so the follower can redirect clients
  server_id: ulong;
  /// caller's term
  term: ulong;

  /// the snapshot covers the range [1, lastSnapshotIndex]
  last_snapshot_index: ulong;

  /// the byte offset where the 'data' belongs in the file. Followers can
  /// expect this to grow without gaps. They should use this to drop duplicate
  /// messages/requests
  byte_offset: ulong;

  /// raw bytes of the snapshot file. This could be partial RPC for snapshot
  /// see done field
  data: [ubyte];

  /// true if this is the last chunk for the file and the follower should now
  /// load the contents; false otherwise
  done: bool;
}

table install_snapshot_reply {
  ns: long;
  topic: long;
  partition: int;

  /// callee's term, for the caller to update itself;
  term: ulong;
  /// total number of bytes in the snapshot that the follower has stored, after
  /// applying the request;
  bytes_stored: ulong;
}

/// Service API (multi-raft)
// table configuration_request {
//   cfgs: [configuration_request];
// }
// table configuration_reply {
//   cfgs: [configuration_reply];
// }
// table vote_request {
//   votes: [vote_request];
// }
// table vote_reply{
//   votes: [vote_reply];
// }
// table append_entries_request {
//   appends: [append_entries_request];
// }
// table append_entries_reply {
//   appends: [append_entries_reply];
// }
// table install_snapshot_request {
//   snapshots: [install_snapshot_request];
// }
// table install_snapshot_reply {
//   snapshots: [install_snapshot_reply];
// }


rpc_service raft_api {
  /// \brief stores a configuration to be used internally by the consensus
  configuration_update(configuration_request): configuration_reply;

  /// \brief ask a server for its vote in an election algorithm
  vote(vote_request): vote_reply;

  /// \brief used to replicate logs to the follower
  append_entries(append_entries_request): append_entries_reply;

  /// \brief replicate part of a snapshot file to a follower.
  install_snapshot(install_snapshot_request): install_snapshot_reply;


  /// \brief can only happen in one of the seed servers.
  create_topic(wal_topic_create_request): wal_topic_create_reply;

  // TODO(agallego) reply
  /// \brief an specialized form of append_entries.
  internal_create_topic(wal_topic_create_request): wal_topic_create_reply;
}


// -- internal api

enum log_index_topic_key_type:byte {
  none,
  configuration,
  voted_for
}

struct log_index_topic_key {
  version: byte;
  key: log_index_topic_key_type;
  ns: long;
  topic: long;
  partition: int;
}

struct log_index_voted_for {
  voted_for: long;
}
